This file will guide you on how to use this program.
First of all you will need following libraries 
soundfile numpy matplotlib math 

There are mainly 4 python files in this folder
1. FFT.py
    This is the base code of this whole program. It does
        -Takes the input discrete signal form the .wav file named -"my_recording.wav"
        -Pre-emphasis of a signal
        -Frames and hop
        -Implementing window(hanning) on each Frames
        -Performing FFT on each windowed frame

2. melFilterBank.py 
    This is the python file based on FFT.py. It does 
        -hz to melscale conversion 
        -taking natural log on melscale 
        -ln(melscale)  to hz conversion 
        -frequency to fft bins conversion 
        -implement triangular filter bank using the converted fft bins.
        -a total of 26 triangular filter bank are taken 
        -calculate the weight for each frequency bins
        -mel scale energy calculate. Each triangular filter return one energy value.

3. DCT.py 
    This is the final file for MFCCs calculation. It performs
        -Discrete Cosine transform on each frame's computed mel scale energy -26 values
        -only the first 13 values are taken for each frame excluding the 0th value.
        -A feature vector is computed, mean of each corresponding index coefficients of all frame.

4.KNNForMFCCs.py 
    It is basically a KNN algorithm modified specially for recognition of MFCCs. It performs
        -It takes the calculated feature vector of the audio file my_recording.wav as input during runtime.
        -C is a 2D vector which store the known MFCCs with first index of each row storing a string for corresponding letter/word
        -computedistance is a function which basically calculate the distance between the 13 dimension coordinates of unknown input
        MFCCs and known MFCCs values of C 
        -If the nearest MFCCs lies in the range of threshold then it returns the label else it return unknown.


RUNNING THE PROGRAM 
    You can record you sound using the file RecordYourVoice.py. Do not ulter the recording length if you want to use the provided
    MFCCs values
    -Run the file KNNFORMFCCs.py to recognize the letter/word spoken in the file my_recording.wav
    -Run the file DCT.py to plot the heat map of the MFCCs.
    -Run the file FFT.py to plot the time and frequency domain representation of windowed ith frame
    -Run the file melFilterBank.py to plot the MFCCs of ith frame. 



NOTE:
    - The KNOWN MFCCs values are calculated using my own voice and inside a room. The MFCCs vary according to the 
        environment. So for better result record your own audio and calculate MFCCs and add it in the vector C as known MFCCs
        with first element of the row being the letter or word spoken 
    
    - The known MFCCs value are recorded in time frame of 1s and the frames taken for calculation starts after 0.5s.
        So MFCCs values will vary if you alter the length of the audio. So keep the audio length 1s if you want to use the
        provided MFCCs else calculate the MFCCs yourself and add it in the list of known MFCCs.



